/**
 * Gets the stage name for this job
 * @return String
 */
def getStageName() {
    return env.BRANCH_NAME == "master" ? "dev" : env.BRANCH_NAME
}

pipeline {

    agent { node { label 'ubuntu-18.04-worker' } }

    environment {
        STAGE = getStageName()
        SLACK_CHANNEL = '#alerts-data-platform'

        // Namespaces docker-compose to not compete with concurrent builds
        COMPOSE_PROJECT_NAME = "dewey-spark-ci-${env.BRANCH_NAME}-${currentBuild.id}"

        // The lowest-allowable pylint score
        PYLINT_THRESHOLD="4.80"

        // AWS Settings
        AWS_DEFAULT_REGION = 'us-east-1'
        AWS_ACCESS_KEY_ID = sh(script: "curl -s http://169.254.169.254/latest/meta-data/iam/security-credentials/jenkins_worker | jq -r '.AccessKeyId'", , returnStdout: true).trim()
        AWS_SECRET_ACCESS_KEY = sh(script: "curl -s http://169.254.169.254/latest/meta-data/iam/security-credentials/jenkins_worker | jq -r '.SecretAccessKey'", , returnStdout: true).trim()
        AWS_SESSION_TOKEN = sh(script: "curl -s http://169.254.169.254/latest/meta-data/iam/security-credentials/jenkins_worker | jq -r '.Token'", , returnStdout: true).trim()
    }

    stages {

        stage('Build') {
            steps {
                sh 'cd spark && make build-container'
            }
        }

        stage('QA') {
            parallel {  
                stage('Unit tests') {
                    steps {
                        sh 'cd spark && make test-python3'
                    }
                }

                stage('Lint') {
                    steps {
                        sh 'cd spark && make lint-python'
                    }
                }
            }
        }
    }

    post {
        cleanup {
            cleanWs();
        }
    }
}
